{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 로이터 뉴스 데이터셋 불러오기\n",
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러온 데이터를 학습 셋과 테스트셋으로 나누기\n",
    "(X_train, Y_train), (X_test, Y_test) = reuters.load_data(num_words = 1000, test_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 카테고리\n",
      "8982 학습용 뉴스 기사\n",
      "2246 테스트용 뉴스 기사\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 2, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 2, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인 후 출력\n",
    "category = np.max(Y_train) + 1\n",
    "print(category, '카테고리')\n",
    "print(len(X_train), '학습용 뉴스 기사')\n",
    "print(len(X_test), '테스트용 뉴스 기사')\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "# 데이터 전처리\n",
    "x_train = sequence.pad_sequences(X_train, maxlen = 100)\n",
    "x_test = sequence.pad_sequences(X_test, maxlen = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(Y_train)\n",
    "y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "# 모델의 설정\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000, 100))\n",
    "model.add(LSTM(100, activation = 'tanh'))\n",
    "model.add(Dense(46, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/20\n",
      "8982/8982 [==============================] - 17s 2ms/step - loss: 2.6005 - accuracy: 0.3466 - val_loss: 2.4084 - val_accuracy: 0.3620\n",
      "Epoch 2/20\n",
      "8982/8982 [==============================] - 16s 2ms/step - loss: 2.2007 - accuracy: 0.4458 - val_loss: 2.0876 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "8982/8982 [==============================] - 16s 2ms/step - loss: 1.9703 - accuracy: 0.5006 - val_loss: 1.8979 - val_accuracy: 0.5232\n",
      "Epoch 4/20\n",
      "8982/8982 [==============================] - 16s 2ms/step - loss: 1.8137 - accuracy: 0.5274 - val_loss: 1.7564 - val_accuracy: 0.5499\n",
      "Epoch 5/20\n",
      "8982/8982 [==============================] - 16s 2ms/step - loss: 1.7143 - accuracy: 0.5562 - val_loss: 1.8230 - val_accuracy: 0.5245\n",
      "Epoch 6/20\n",
      "8982/8982 [==============================] - 17s 2ms/step - loss: 1.6544 - accuracy: 0.5758 - val_loss: 1.6638 - val_accuracy: 0.5824\n",
      "Epoch 7/20\n",
      "8982/8982 [==============================] - 16s 2ms/step - loss: 1.5787 - accuracy: 0.6009 - val_loss: 1.6220 - val_accuracy: 0.6077\n",
      "Epoch 8/20\n",
      "8982/8982 [==============================] - 16s 2ms/step - loss: 1.5261 - accuracy: 0.6149 - val_loss: 1.5280 - val_accuracy: 0.6242\n",
      "Epoch 9/20\n",
      "8982/8982 [==============================] - 16s 2ms/step - loss: 1.4040 - accuracy: 0.6472 - val_loss: 1.5019 - val_accuracy: 0.6278\n",
      "Epoch 10/20\n",
      "8982/8982 [==============================] - 16s 2ms/step - loss: 1.3340 - accuracy: 0.6642 - val_loss: 1.4363 - val_accuracy: 0.6456\n",
      "Epoch 11/20\n",
      "8982/8982 [==============================] - 16s 2ms/step - loss: 1.2657 - accuracy: 0.6820 - val_loss: 1.3978 - val_accuracy: 0.6558\n",
      "Epoch 12/20\n",
      "8982/8982 [==============================] - 16s 2ms/step - loss: 1.2125 - accuracy: 0.6895 - val_loss: 1.3477 - val_accuracy: 0.6656\n",
      "Epoch 13/20\n",
      "8982/8982 [==============================] - 16s 2ms/step - loss: 1.1581 - accuracy: 0.7043 - val_loss: 1.3280 - val_accuracy: 0.6670\n",
      "Epoch 14/20\n",
      "4800/8982 [===============>..............] - ETA: 7s - loss: 1.1017 - accuracy: 0.7119"
     ]
    }
   ],
   "source": [
    "# 모델의 컴파일\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = ['accuracy'])\n",
    "# 모델의 실행\n",
    "history = model.fit(x_train, y_train, batch_size = 100, epochs = 20, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 정확도 출력\n",
    "print('\\n Test Accuracy : %.4f' % (model.eva))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM을 이용해 로이터 뉴스 카테고리 분석하기\n",
    "from keras.datasets import reutets\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러온 데이터를 학습셋과 테스트셋으로 나누기\n",
    "(X_train, Y_train), (X_test, Y_test) = reuters.load_data(num_words = 1000, test_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인하기\n",
    "category = np.max(Y_train) + 1\n",
    "print(category, '카테고리')\n",
    "print(len(X_train), '학습용 뉴스 기사' )\n",
    "print(len(X_test), '테스트용 뉴스 기사')\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
